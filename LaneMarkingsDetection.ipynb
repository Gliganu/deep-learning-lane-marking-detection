{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1080 (CNMeM is disabled, cuDNN 5110)\n",
      "/opt/conda/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import math\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, MaxoutDense\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
    "from keras.layers import Embedding,GRU,TimeDistributed,RepeatVector,Merge,Input,merge,UpSampling2D\n",
    "from matplotlib.patches import Circle\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import re\n",
    "from numpy.random import random, permutation, randn, normal \n",
    "import PIL.Image\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "import cPickle as pickle\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from itertools import compress\n",
    "\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import collections\n",
    "\n",
    "import bcolz\n",
    "import cPickle as pickle\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import cv2\n",
    "\n",
    "from skimage.transform import (hough_line, hough_line_peaks,\n",
    "                               probabilistic_hough_line)\n",
    "\n",
    "from IPython.display import Image, display, SVG\n",
    "from keras.utils.visualize_util import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nr_of_examples(df_path):\n",
    "    \n",
    "    split_paths = [split_path for split_path in os.listdir(df_path)]\n",
    "    split_paths.sort()\n",
    "    \n",
    "    nr_examples = 0\n",
    "    \n",
    "    for split_path in tqdm(split_paths):\n",
    "\n",
    "        data_df_split = pd.read_pickle(df_path + split_path)\n",
    "        \n",
    "        nr_examples += len(data_df_split)\n",
    "    \n",
    "    return nr_examples\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "def auto_canny(image, sigma=0.33):\n",
    "    v = np.median(image)\n",
    "\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    \n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    "\n",
    "    return edged\n",
    "\n",
    "\n",
    "def read_roma_paths(folders):\n",
    "    \n",
    "    all_img_paths = []\n",
    "    all_mask_paths = []\n",
    "\n",
    "    for folder in folders:\n",
    "        img_paths = sorted([folder+path for path in os.listdir(folder) if \".jpg\" in path])\n",
    "        mask_paths = sorted([folder+path for path in os.listdir(folder) if \".pgm\" in path])\n",
    "\n",
    "        all_img_paths += img_paths\n",
    "        all_mask_paths += mask_paths\n",
    "        \n",
    "    return all_img_paths, all_mask_paths\n",
    "\n",
    "def arr(img):\n",
    "    return np.asarray(img)\n",
    "    \n",
    "\n",
    "\n",
    "def crop_resize_data(imgs,masks,new_img_size):\n",
    "    \n",
    "    cropped_imgs = []\n",
    "    cropped_masks = []\n",
    "    \n",
    "    for img,mask in tqdm(zip(imgs,masks)):\n",
    "        cropped_img, cropped_mask = get_vp_img_based_on_haugh(img,mask)\n",
    "        \n",
    "        cropped_img = cropped_img.resize((new_img_size,new_img_size), PIL.Image.NEAREST)\n",
    "        cropped_mask = cropped_mask.resize((new_img_size,new_img_size), PIL.Image.NEAREST)\n",
    "        \n",
    "        if(len(arr(cropped_mask).shape) == 3):\n",
    "            cropped_mask = arr(cropped_mask)[...,0]\n",
    "        \n",
    "        cropped_imgs.append(arr(cropped_img))\n",
    "        cropped_masks.append(np.expand_dims(arr(cropped_mask),axis=3))\n",
    "        \n",
    "    return np.stack(cropped_imgs),np.stack(cropped_masks)\n",
    "\n",
    "def plot_predicted_vs_ground_truth(images, masks, predictions, nr_imgs = None):\n",
    "        \n",
    "    if(nr_imgs == None):\n",
    "        nr_imgs = len(images)\n",
    "        \n",
    "    for index in tqdm(range(nr_imgs)):\n",
    "   \n",
    "        raw_pred = predictions[index]\n",
    "        squeezed_pred = np.squeeze(raw_pred)\n",
    "\n",
    "        raw_mask = masks[index]\n",
    "        raw_mask = np.squeeze(raw_mask)\n",
    "        \n",
    "        image = images[index]\n",
    "    \n",
    "        nr_cols = 3\n",
    "        \n",
    "        plt.subplot(1,nr_cols,1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.subplot(1,nr_cols,2)\n",
    "        plt.imshow(raw_mask)\n",
    "        \n",
    "        plt.subplot(1,nr_cols,3)\n",
    "        plt.imshow(squeezed_pred)\n",
    "       \n",
    "        plt.figure(figsize=(10,10))\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def line(p1, p2):\n",
    "    A = (p1[1] - p2[1])\n",
    "    B = (p2[0] - p1[0])\n",
    "    C = (p1[0]*p2[1] - p2[0]*p1[1])\n",
    "    return A, B, -C\n",
    "\n",
    "def intersection(L1, L2):\n",
    "    D  = L1[0] * L2[1] - L1[1] * L2[0]\n",
    "    Dx = L1[2] * L2[1] - L1[1] * L2[2]\n",
    "    Dy = L1[0] * L2[2] - L1[2] * L2[0]\n",
    "    if D != 0:\n",
    "        x = Dx / D\n",
    "        y = Dy / D\n",
    "        return x,y\n",
    "\n",
    "    return False\n",
    "  \n",
    "\n",
    "def get_vp_img_based_on_haugh(original_image,original_mask):\n",
    "    \n",
    "    original_image_width, original_image_height = original_image.size\n",
    "        \n",
    "    resized_img = original_image.resize((448,448), PIL.Image.NEAREST)\n",
    "    resized_img_width, resized_img_height = resized_img.size\n",
    "    \n",
    "    resized_img = np.asarray(resized_img)\n",
    "    canny_img = auto_canny(resized_img)\n",
    "        \n",
    "    h, theta, d = hough_line(canny_img)\n",
    "    \n",
    "    peaks = None\n",
    "    peaks = zip(*hough_line_peaks(h, theta, d, threshold=25))\n",
    "    nr_peaks = 5\n",
    "    \n",
    "\n",
    "    angle_2_dist_list = []\n",
    "    \n",
    "    for _, angle, dist in peaks[:nr_peaks]:\n",
    "        if(angle < 1.5 and angle > -1.5):\n",
    "            angle_2_dist_list.append((angle,dist))\n",
    "    \n",
    "    if(len(angle_2_dist_list) < 2):\n",
    "        return original_image,original_mask\n",
    "    \n",
    "        \n",
    "    angle_2_dist_list = sorted(angle_2_dist_list, key=lambda tup: tup[0])\n",
    "\n",
    "    selected_angle_dist_list = [angle_2_dist_list[0],angle_2_dist_list[len(angle_2_dist_list)-1]]\n",
    "\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for angle,dist in selected_angle_dist_list:\n",
    "        y0 = (dist - 0 * np.cos(angle)) / np.sin(angle)\n",
    "        y1 = (dist - canny_img.shape[1] * np.cos(angle)) / np.sin(angle)\n",
    "        \n",
    "        lines.append(([0,y0],[canny_img.shape[1],y1]))\n",
    "      \n",
    "    L1 = line(lines[0][0],lines[0][1])\n",
    "    L2 = line(lines[1][0],lines[1][1])\n",
    "    \n",
    "    R = intersection(L1, L2)\n",
    "    \n",
    "    if (not R):\n",
    "        return original_image,original_mask\n",
    "    \n",
    "    new_width = max(0,int(R[0]))\n",
    "    new_width = min(resized_img_width,new_width)\n",
    "    \n",
    "    new_height = max(0,int(R[1]))\n",
    "    new_height = min(resized_img_height,new_height)\n",
    "\n",
    "    height_percentage = float(new_height) / resized_img_height\n",
    "    vp_width_percentage = float(new_width) / resized_img_width\n",
    "    \n",
    "    if(height_percentage == 1):\n",
    "        return original_image,original_mask\n",
    "    \n",
    "    original_img_new_height = int(original_image_height * height_percentage)\n",
    "    \n",
    "    cropped_img = original_image.crop((0,original_img_new_height,original_image_width,original_image_height))\n",
    "    cropped_mask = original_mask.crop((0,original_img_new_height,original_image_width,original_image_height))\n",
    "    \n",
    "    return cropped_img,cropped_mask   \n",
    "\n",
    "\n",
    "def rotate_image(image,angle):\n",
    "    height, width, _ = image.shape\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((width / 2, height / 2), angle, 1.0)\n",
    "    result = cv2.warpAffine(image, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR)\n",
    "    return result\n",
    "    \n",
    "def rotate_image_cw(img):\n",
    "    return rotate_image(img,-15)\n",
    "\n",
    "def rotate_image_ccw(img):\n",
    "    return rotate_image(img,15)\n",
    "\n",
    "def flip_image(img):\n",
    "    return cv2.flip(img,1)\n",
    "\n",
    "def read_camvid_mask(path):\n",
    "    \n",
    "    mask = arr(PIL.Image.open(path).resize((480,360))).copy()\n",
    "    \n",
    "    idx = (mask[...,0] == 128) & (mask[...,1] == 0) & (mask[...,2] == 192)\n",
    "    not_idx = np.logical_not(idx)\n",
    "\n",
    "    mask[idx] = 1\n",
    "    mask[not_idx] = 0\n",
    "    \n",
    "    return PIL.Image.fromarray(mask)\n",
    "\n",
    "\n",
    "def normalize_imgs(data):\n",
    "    \n",
    "    data = data.astype('float32')\n",
    "\n",
    "    mean = np.mean(data)  # mean for data centering\n",
    "    std = np.std(data)  # std for data normalization\n",
    "\n",
    "    data -= mean\n",
    "    data /= std\n",
    "    \n",
    "    return data\n",
    "\n",
    "def transform_camvid_masks(camvid_mask_paths):\n",
    "    \n",
    "    for path in tqdm(camvid_mask_paths):\n",
    "        img_name = os.path.basename(path)\n",
    "        marking_mask = read_camvid_mask(path)\n",
    "        output_path = \"../datasets/camvid/rm_masks/\"+img_name\n",
    "        marking_mask.save(output_path)\n",
    "        \n",
    "    \n",
    "def get_roma_img_mask_paths(roma_dataset_path):\n",
    "    roma_folders = [roma_dataset_path + folder+\"/\" for folder in os.listdir(roma_dataset_path)]\n",
    "    img_paths, mask_paths = read_roma_paths(roma_folders)\n",
    "    \n",
    "    data_df = pd.DataFrame({\n",
    "        'img_path': img_paths,\n",
    "        'img_name': [os.path.basename(path) for path in img_paths],\n",
    "        'mask_path': mask_paths\n",
    "    })\n",
    "    \n",
    "    data_df = data_df.set_index('img_name')\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "def get_camvid_img_mask_paths(camvid_dataset_path):\n",
    "\n",
    "    camvid_img_path = camvid_dataset_path + \"imgs/\"\n",
    "    camvid_mask_path = camvid_dataset_path + \"rm_masks/\"\n",
    "    \n",
    "    img_paths = [camvid_img_path + path for path in sorted(os.listdir(camvid_img_path))]\n",
    "    mask_paths = [camvid_mask_path + path for path in sorted(os.listdir(camvid_mask_path))]\n",
    "  \n",
    "    data_df = pd.DataFrame({\n",
    "        'img_path': img_paths,\n",
    "        'img_name': [os.path.basename(path) for path in img_paths],\n",
    "        'mask_path': mask_paths\n",
    "    })\n",
    "    \n",
    "    data_df = data_df.set_index('img_name',)\n",
    "    \n",
    "    return data_df\n",
    "\n",
    "\n",
    "def get_data_from_paths(img_paths, mask_paths, nr_imgs = None):\n",
    "      \n",
    "    if(nr_imgs == None):\n",
    "        nr_imgs = len(img_paths)\n",
    "    \n",
    " \n",
    "    masks = [PIL.Image.open(path) for path in tqdm(mask_paths[:nr_imgs])]\n",
    "    \n",
    "    imgs = shuffle(imgs, random_state=0)\n",
    "    masks = shuffle(masks, random_state=0)\n",
    "\n",
    "    return imgs,masks\n",
    "\n",
    "def plot_img_mask(imgs,masks,nr_to_plot = None):\n",
    "       \n",
    "    if(nr_to_plot == None):\n",
    "        nr_imgs = len(imgs)\n",
    "   \n",
    "    for i in range(10):\n",
    "    \n",
    "        img = imgs[i]\n",
    "        mask = np.squeeze(masks[i])\n",
    "\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(img)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(mask)\n",
    "\n",
    "        plt.figure()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "def numpify(series):  \n",
    "    return np.stack(series.tolist())\n",
    "\n",
    "def split_train_test(data_df, train_percentage):\n",
    "    \n",
    "    nr_train = int(train_percentage * len(data_df))\n",
    "    train_df = data_df[:nr_train]\n",
    "    test_df = data_df[nr_train:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "    \n",
    "def read_data(img_path, mask_path, new_img_size):\n",
    "    img =  PIL.Image.open(img_path).resize((new_img_size,new_img_size))\n",
    "    mask = PIL.Image.open(mask_path).resize((new_img_size,new_img_size))\n",
    "    \n",
    "    #mask = np.squeeze(mask).copy()\n",
    "        \n",
    "    if(len(arr(mask).shape) != 2):\n",
    "        mask = arr(mask)[...,0]\n",
    "        \n",
    "    mask = arr(mask) / 255.\n",
    "    \n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    \n",
    "    return pd.Series({'img': img, \\\n",
    "                      'mask': mask})\n",
    "\n",
    "def construct_batch((data_df_split, df_path, img_path, mask_path, index, new_img_size)):\n",
    "        \n",
    "        \n",
    "    data_df_split = pd.concat([data_df_split, data_df_split.apply(lambda row : \\\n",
    "                                                                  read_data(row['img_path'],\\\n",
    "                                                                             row['mask_path'],\\\n",
    "                                                                             new_img_size),axis=1)],axis=1)\n",
    "\n",
    "    imgs = data_df_split['img']\n",
    "    masks = data_df_split['mask']\n",
    "\n",
    "    imgs, masks = crop_resize_data(imgs,masks,new_img_size)\n",
    "    \n",
    "    data_df_split = data_df_split.drop('img',axis=1).drop('mask',axis=1)\n",
    "    \n",
    "    batch_save_name = \"data_df_split_\"+str(format(index, \"04\"))\n",
    "    \n",
    "    data_df_split.to_pickle(df_path + batch_save_name + \"_df.pkl\")\n",
    "    \n",
    "    np.save(img_path + batch_save_name + \"_img.dat\",imgs)\n",
    "    np.save(mask_path + batch_save_name + \"_mask.dat\",masks)\n",
    "    \n",
    "    \n",
    "def construct_data_batches(data_df, df_path, img_path, mask_path, new_img_size):\n",
    "\n",
    "    create_folder(df_path)\n",
    "    create_folder(img_path)\n",
    "    create_folder(mask_path)\n",
    "    \n",
    "    nr_splits = max(1,int(float(len(data_df)) / NR_ENTRIES_PER_SPLIT) + 1)\n",
    "    \n",
    "    print(\"Nr splits = {}\".format(nr_splits))\n",
    "    \n",
    "    data_df_splits = np.array_split(data_df, nr_splits)\n",
    "    \n",
    "    df_path_list = [df_path] * nr_splits\n",
    "    img_path_list = [img_path] * nr_splits\n",
    "    mask_path_list = [mask_path] * nr_splits\n",
    "    indexes = range(nr_splits)\n",
    "    new_img_size_list = [new_img_size] * nr_splits\n",
    "    \n",
    "    all_data = zip(data_df_splits, df_path_list, img_path_list, mask_path_list, indexes, new_img_size_list)\n",
    "    \n",
    "    for data_df_split, df_path, img_path, mask_path, index, new_img_size in tqdm(all_data):\n",
    "        df = construct_batch((data_df_split, df_path, img_path, mask_path, index, new_img_size))\n",
    "\n",
    "#     pool = Pool(8)\n",
    "#     pool.map(construct_batch,all_data)\n",
    "\n",
    "\n",
    "\n",
    "def merge_df_with_data(df_path,img_path,mask_path):\n",
    "    \n",
    "    batch_df = pd.read_pickle(df_path)    \n",
    "\n",
    "    imgs = np.load(img_path)\n",
    "    masks = np.load(mask_path)\n",
    "    \n",
    "    batch_df.loc[:,'img'] = [img for img in imgs]\n",
    "    batch_df.loc[:,'mask'] = [mask for mask in masks]\n",
    "    \n",
    "    return batch_df\n",
    "\n",
    "\n",
    "def read_data_batches_in_df(df_path, img_path, mask_path, nr_batches = None):\n",
    "    \n",
    "    df_batches_paths = sorted([df_path + path for path in os.listdir(df_path)])\n",
    "    img_batches_paths = sorted([img_path + path for path in os.listdir(img_path)])\n",
    "    mask_batches_paths = sorted([mask_path + path for path in os.listdir(mask_path)])\n",
    "        \n",
    "    if(nr_batches == None):\n",
    "        nr_batches = len(df_batches_paths)\n",
    "        \n",
    "    df_batches_paths = df_batches_paths[:nr_batches]\n",
    "    img_batches_paths = img_batches_paths[:nr_batches]\n",
    "    mask_batches_paths = mask_batches_paths[:nr_batches]\n",
    "    \n",
    "    return pd.concat([merge_df_with_data(df_path, img_path , mask_path) \\\n",
    "                               for df_path, img_path, mask_path in tqdm(zip(df_batches_paths,\\\n",
    "                                                                            img_batches_paths,\\\n",
    "                                                                            mask_batches_paths ))],axis=0)\n",
    "\n",
    "def rotate_image_cw(img):\n",
    "    return rotate_image(img,-15)\n",
    "\n",
    "def rotate_image_ccw(img):\n",
    "    return rotate_image(img,15)\n",
    "\n",
    "def flip_image(img):\n",
    "    return cv2.flip(img,1)\n",
    "\n",
    "\n",
    "def get_augment_techniques():\n",
    "    return [(\"flip\",flip_image),\n",
    "            (\"rotate_cw\",rotate_image_cw),\n",
    "            (\"rotate_ccw\",rotate_image_ccw)\n",
    "           ]\n",
    "\n",
    "def augment_batches(df_path, img_path, mask_path, new_img_size):\n",
    "    \n",
    "    batch_paths = sorted([batch_path for batch_path in os.listdir(df_path) if \"augm\" not in batch_path])\n",
    "    \n",
    "    print(\"Nr batches = {}\".format(len(batch_paths)))\n",
    "    \n",
    "    for index,batch_path in tqdm(list(enumerate(batch_paths))):\n",
    "        \n",
    "        batch_name = batch_path.split(\".\")[0][:-3]\n",
    "\n",
    "        batch_data_df = pd.read_pickle(df_path + batch_path)\n",
    "\n",
    "        batch_imgs = np.load(img_path + batch_name + \"_img.dat.npy\")\n",
    "        batch_masks = np.load(mask_path + batch_name + \"_mask.dat.npy\")\n",
    "        \n",
    "        for name,augment_function in get_augment_techniques():\n",
    "            \n",
    "            augm_df_batch_name = batch_name+\"_\"+name+\"_df_augm\"\n",
    "            augm_mask_batch_name = batch_name+\"_\"+name+\"_mask_augm\"\n",
    "            augm_img_batch_name = batch_name+\"_\"+name+\"_img_augm\"\n",
    "\n",
    "            augm_img = np.stack([augment_function(img) for img in batch_imgs])\n",
    "            augm_mask = np.stack([augment_function(mask) for mask in batch_masks])\n",
    "            augm_mask = np.expand_dims(augm_mask,axis=3)\n",
    "            \n",
    "            batch_data_df.to_pickle(df_path+augm_df_batch_name+\".pkl\") # same df\n",
    "            np.save(img_path + augm_img_batch_name + \".dat\",augm_img)\n",
    "            np.save(mask_path + augm_mask_batch_name + \".dat\",augm_mask)\n",
    "        \n",
    "        \n",
    "def compute_global_mean(img_path):\n",
    "    \n",
    "    split_paths = sorted([img_path + split_path for split_path in os.listdir(img_path)])\n",
    "\n",
    "    batch_lengths = []\n",
    "    batch_averages = []\n",
    "    \n",
    "    for split_path in tqdm(split_paths):\n",
    "\n",
    "        img_batch = np.load(split_path)\n",
    "        \n",
    "        nr_imgs ,img_width, img_height, nr_color_channels = img_batch.shape\n",
    "        \n",
    "        img_batch = img_batch.reshape((nr_imgs, img_width*img_height, nr_color_channels))\n",
    "\n",
    "        avg_per_pic = np.average(img_batch,axis=1)\n",
    "        batch_avg = np.average(avg_per_pic,axis=0)\n",
    "        \n",
    "        batch_lengths.append(len(img_batch))        \n",
    "        batch_averages.append(batch_avg)\n",
    "\n",
    "    global_avg = np.average(arr(batch_averages),weights = arr(batch_lengths), axis=0)\n",
    "    \n",
    "    return global_avg.astype(np.float32).reshape((3,1,1))\n",
    "\n",
    "def data_generator(img_path, mask_path):\n",
    "    \n",
    "    batch_img_paths = sorted([img_path + batch_path for batch_path in os.listdir(img_path)])\n",
    "    batch_mask_paths = sorted([mask_path + batch_path for batch_path in os.listdir(mask_path)])\n",
    "    \n",
    "    nr_batches = len(batch_img_paths)\n",
    "        \n",
    "    while(1):\n",
    "        \n",
    "        for batch_img_path, batch_mask_path in zip(batch_img_paths,batch_mask_paths):\n",
    "                        \n",
    "            imgs = np.load(batch_img_path)\n",
    "            masks = np.load(batch_mask_path)\n",
    "        \n",
    "            imgs = np.transpose(imgs,(0,3,1,2))\n",
    "            masks = np.transpose(masks,(0,3,1,2))\n",
    "\n",
    "            yield(imgs,masks)\n",
    "\n",
    "def get_pred_df(data_df, model):\n",
    "    \n",
    "    img_data = numpify(data_df['img'])\n",
    "    img_data = np.transpose(img_data,(0,3,1,2))\n",
    "    \n",
    "    predictions = model.predict(img_data,verbose=1)\n",
    "    \n",
    "    data_df.loc[:,'pred'] = pd.Series([pred for pred in predictions], index = data_df.index)\n",
    "    \n",
    "    return data_df\n",
    "  \n",
    "    \n",
    "def make_prediction_on_dataset(df_path, img_path, mask_path, model, nr_batches = None):\n",
    "\n",
    "    batch_df_paths = sorted([df_path + batch_path for batch_path in os.listdir(df_path)])\n",
    "    batch_img_paths = sorted([img_path + batch_path for batch_path in os.listdir(img_path)])\n",
    "    batch_mask_paths = sorted([mask_path + batch_path for batch_path in os.listdir(mask_path)])\n",
    "\n",
    "    if(nr_batches == None):\n",
    "        nr_batches = len(batch_df_paths)\n",
    "    \n",
    "    pred_df = []\n",
    "        \n",
    "    for batch_df_path, batch_img_path, batch_mask_path in tqdm(zip(batch_df_paths, \\\n",
    "                                                                   batch_img_paths, \\\n",
    "                                                                   batch_mask_paths)[:nr_batches]):\n",
    "        \n",
    "        data_df_split = merge_df_with_data(batch_df_path,batch_img_path,batch_mask_path)\n",
    "        \n",
    "        pred_df_split = get_pred_df(data_df_split, model)\n",
    "                \n",
    "        pred_df.append(pred_df_split)\n",
    "       \n",
    "    pred_df = pd.concat(pred_df,axis=0)\n",
    "    \n",
    "    return pred_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_img_size = 448\n",
    "NR_ENTRIES_PER_SPLIT = 8\n",
    "\n",
    "roma_dataset_path =  \"../datasets/roma-dataset/\"\n",
    "camvid_dataset_path = \"../datasets/camvid/\"\n",
    "\n",
    "base_path = \"./data/\"\n",
    "\n",
    "train_base_path = base_path + \"train/\"\n",
    "test_base_path = base_path + \"test/\"\n",
    "\n",
    "train_df_path = train_base_path +\"df/\"\n",
    "train_img_path = train_base_path +\"img/\"\n",
    "train_mask_path = train_base_path +\"mask/\"\n",
    "\n",
    "test_df_path = test_base_path +\"df/\"\n",
    "test_img_path = test_base_path +\"img/\"\n",
    "test_mask_path = test_base_path +\"mask/\"\n",
    "\n",
    "create_folder(train_base_path)\n",
    "create_folder(test_base_path)\n",
    "\n",
    "create_folder(train_df_path)\n",
    "create_folder(train_img_path)\n",
    "create_folder(train_mask_path)\n",
    "\n",
    "create_folder(test_df_path)\n",
    "create_folder(test_img_path)\n",
    "create_folder(test_mask_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "roma_df = get_roma_img_mask_paths(roma_dataset_path)\n",
    "# camvid_df = get_camvid_img_mask_paths(camvid_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_df = shuffle(pd.concat([roma_df,camvid_df]),random_state = 0)\n",
    "data_df = roma_df\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_PERCENTAGE = 0.8\n",
    "\n",
    "train_df, test_df = split_train_test(data_df, TRAIN_PERCENTAGE)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Construct Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "construct_data_batches(train_df, train_df_path, train_img_path, train_mask_path, new_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "construct_data_batches(test_df, test_df_path, test_img_path, test_mask_path, new_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Viz Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split_df = read_data_batches_in_df(train_df_path, train_img_path, train_mask_path, nr_batches = 2)\n",
    "\n",
    "for _,row in tqdm(list(split_df.iterrows())):\n",
    "    img = row['img']\n",
    "    mask = np.squeeze(row['mask'])\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(mask)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(mask,alpha=0.5)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "augment_batches(train_df_path, train_img_path, train_mask_path, new_img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "global_mean = compute_global_mean(train_img_path)\n",
    "global_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg_preprocess(x):\n",
    "    x = x - global_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "def get_unet(img_width, img_height):\n",
    "\n",
    "    inputs = Input((3, img_width, img_height))\n",
    "    x = Lambda(vgg_preprocess, output_shape = (3, 448, 448))(inputs)\n",
    "    \n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(x)\n",
    "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
    "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
    "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
    "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)\n",
    "\n",
    "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
    "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)\n",
    "\n",
    "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
    "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)\n",
    "\n",
    "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
    "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)\n",
    "\n",
    "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
    "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
    "\n",
    "    conv10 = Convolution2D(1, 1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input=inputs, output=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nr_train_data = get_nr_of_examples(train_df_path)\n",
    "nr_test_data = get_nr_of_examples(test_df_path)\n",
    "\n",
    "print(nr_train_data)\n",
    "print(nr_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_unet(new_img_size, new_img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure = SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n",
    "# display(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(data_generator(train_img_path, train_mask_path),\n",
    "      samples_per_epoch = nr_train_data ,\n",
    "      nb_epoch= 3,               \n",
    "      validation_data = data_generator(test_img_path, test_mask_path),\n",
    "      nb_val_samples = nr_test_data, \n",
    "      callbacks = [#CSVLogger(\"./training.txt\"), \\\n",
    "                   #ModelCheckpoint(\"./models-new/model_temp.h5\", monitor='val_acc', verbose= 1, save_best_only=True, mode='max')\n",
    "                  ]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"./1e_batch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"./1e_batch.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_data_df = make_prediction_on_dataset(test_df_path, test_img_path, test_mask_path, model, nr_batches = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _, row in tqdm(list(pred_data_df.iterrows())):\n",
    "    \n",
    "    img = row['img']\n",
    "    mask = np.squeeze(row['mask'])\n",
    "    pred = np.squeeze(row['pred'])\n",
    "    \n",
    "    nr_cols = 3\n",
    "\n",
    "#     plt.subplot(1,nr_cols,1)\n",
    "#     plt.imshow(img)\n",
    "\n",
    "#     plt.subplot(1,nr_cols,2)\n",
    "#     plt.imshow(mask)\n",
    "\n",
    "#     plt.subplot(1,nr_cols,3)\n",
    "#     plt.imshow(pred)\n",
    "\n",
    "    _,thresh_pred = cv2.threshold(pred,0.9,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     kernel = np.ones((2,2),np.uint8)\n",
    "#     opening = cv2.morphologyEx(thresh_pred, cv2.MORPH_OPEN, kernel)\n",
    "    img_canny = auto_canny(img.astype(np.uint8),0)\n",
    "    pred_canny = auto_canny(pred.astype(np.uint8),0)\n",
    "    thresh_canny = auto_canny(thresh_pred.astype(np.uint8),0)\n",
    "    \n",
    "#     plt.subplot(1,nr_cols,4)\n",
    "#     plt.imshow(thresh_pred)\n",
    "\n",
    "    plt.subplot(1,nr_cols,1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1,nr_cols,2)\n",
    "    plt.imshow(img_canny)\n",
    "\n",
    "    plt.subplot(1,nr_cols,3)\n",
    "    plt.imshow(thresh_canny)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hough(image,osc_img):\n",
    "    # Classic straight-line Hough transform\n",
    "    h, theta, d = hough_line(image)\n",
    "\n",
    "    # Generating figure 1\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(7, 7),\n",
    "                             subplot_kw={'adjustable': 'box-forced'})\n",
    "    ax = axes.ravel()\n",
    "\n",
    "    ax[0].imshow(image, cmap=cm.gray)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].set_axis_off()\n",
    "\n",
    "    ax[1].imshow(osc_img, cmap=cm.gray)\n",
    "    \n",
    "    peaks = zip(*hough_line_peaks(h, theta, d, threshold=25))\n",
    "    nr_peaks = 5\n",
    "    \n",
    "    if(len(peaks) < nr_peaks):\n",
    "        return\n",
    "    \n",
    "    angle_2_dist_list = []\n",
    "    \n",
    "    \n",
    "    for _, angle, dist in peaks[:nr_peaks]:\n",
    "        if(angle < 1.5 and angle > -1.5):\n",
    "            angle_2_dist_list.append((angle,dist))\n",
    "        \n",
    "    angle_2_dist_list = sorted(angle_2_dist_list, key=lambda tup: tup[0])\n",
    "\n",
    "    selected_angle_dist_list = [angle_2_dist_list[0],angle_2_dist_list[len(angle_2_dist_list)-1]]\n",
    "\n",
    "    \n",
    "    lines = []\n",
    "\n",
    "    for angle,dist in selected_angle_dist_list:\n",
    "                \n",
    "        y0 = (dist - 0 * np.cos(angle)) / np.sin(angle)\n",
    "        y1 = (dist - image.shape[1] * np.cos(angle)) / np.sin(angle)\n",
    "        \n",
    "        ax[1].plot((0, image.shape[1]), (y0, y1), '-r')\n",
    "    \n",
    "        lines.append(([0,y0],[image.shape[1],y1]))\n",
    "        \n",
    "        \n",
    "    L1 = line(lines[0][0],lines[0][1])\n",
    "    L2 = line(lines[1][0],lines[1][1])\n",
    "        \n",
    "    R = intersection(L1, L2)\n",
    "    \n",
    "    r_width, r_height = R\n",
    "    r_height = max(min(r_height,448),0)\n",
    "    r_width = max(min(r_width,448),0)\n",
    "    R = (r_width,r_height)\n",
    "\n",
    "    if(not R):\n",
    "        R = (224,0)\n",
    "\n",
    "    circ = Circle(R,20)\n",
    "    ax[1].add_patch(circ)\n",
    "\n",
    "    \n",
    "    ax[1].set_xlim((0, image.shape[1]))\n",
    "    ax[1].set_ylim((image.shape[0], 0))\n",
    "    ax[1].set_axis_off()\n",
    "    ax[1].set_title('Detected lines ')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "#     return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for _, row in tqdm(list(pred_data_df.iterrows())):\n",
    "    \n",
    "    img = row['img']\n",
    "    pred = np.squeeze(row['pred'])\n",
    "\n",
    "    _,thresh_pred = cv2.threshold(pred,0.9,255,cv2.THRESH_BINARY)\n",
    "    canny = auto_canny(thresh_pred.astype(np.uint8),0)\n",
    "    \n",
    "    plot_hough(canny,img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# OSC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osc_path = \"../datasets/validated-imgs/lane-4/\"\n",
    "osc_img_paths = [osc_path + path for path in sorted(os.listdir(osc_path))]\n",
    "len(osc_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osc_imgs = np.stack([arr(PIL.Image.open(path)) for path in tqdm(osc_img_paths)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index in range(10):\n",
    "    plt.imshow(osc_imgs[index])\n",
    "    plt.figure()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osc_imgs_format = np.transpose(normalize_imgs(osc_imgs),(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "osc_preds = model.predict(osc_imgs_format,verbose = 1, batch_size = 1)\n",
    "osc_preds = np.squeeze(osc_preds)\n",
    "osc_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for osc_img, osc_pred in tqdm(zip(osc_imgs,osc_preds)[:100]):\n",
    "    \n",
    "    _,thresh_pred = cv2.threshold(osc_pred,0.1,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(osc_img)\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(thresh_pred)\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(osc_img)\n",
    "    plt.imshow(thresh_pred,alpha=0.5)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for img,mask in tqdm(zip(imgs,masks)[:100]):\n",
    "        \n",
    "    nr_cols = 3\n",
    "    sq_mask = np.squeeze(mask)\n",
    "    \n",
    "    plt.subplot(1,nr_cols,1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    plt.subplot(1,nr_cols,2)\n",
    "    plt.imshow(sq_mask)\n",
    "\n",
    "    plt.subplot(1,nr_cols,3)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(sq_mask,alpha=0.5)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def plot_slices_merged(plot_images,plot_masks, predictions, nr_slices_in_pic, total_no_images = None):\n",
    "    \n",
    "#     if(total_no_images == None):\n",
    "#         total_no_images = len(plot_images)\n",
    "    \n",
    "#     nr_cols = 3\n",
    "    \n",
    "#     step = int(math.sqrt(nr_slices_in_pic))\n",
    "    \n",
    "#     for i in range(0,total_no_images,nr_slices_in_pic):\n",
    "#         image_slices = plot_images[i:i+nr_slices_in_pic,...]\n",
    "#         mask_slices = plot_masks[i:i+nr_slices_in_pic,...]\n",
    "#         prediction_slices = predictions[i:i+nr_slices_in_pic,...]\n",
    "        \n",
    "#         merged_images = merge_slices(image_slices, step)\n",
    "#         merged_masks = merge_slices(mask_slices, step)\n",
    "#         merged_predictions = merge_slices(prediction_slices, step)\n",
    "        \n",
    "#         plt.subplot(1,nr_cols,1)\n",
    "#         plt.imshow(merged_images)\n",
    "        \n",
    "#         plt.subplot(1,nr_cols,2)\n",
    "#         plt.imshow(np.squeeze(merged_masks))\n",
    "\n",
    "#         plt.subplot(1,nr_cols,3)\n",
    "#         plt.imshow(np.squeeze(merged_predictions))\n",
    "\n",
    "#         plt.figure(figsize=(10,10))\n",
    "        \n",
    "#     plt.show()\n",
    "    \n",
    "# def merge_slices(image_slices,step):\n",
    "#     cols = []\n",
    "#     number_bboxes = len(image_slices)\n",
    "    \n",
    "#     for i in range(0,number_bboxes,step):\n",
    "#         current_col = image_slices[i:i+step,...]\n",
    "#         current_col = np.concatenate(current_col,axis=0)\n",
    "#         cols.append(current_col)\n",
    "#     return np.concatenate(cols,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# def construct_bboxes(image_size, slice_size):\n",
    "                    \n",
    "#     imageWidth = imageHeight = image_size\n",
    "#     sliceHeight = sliceWidth = slice_size\n",
    "    \n",
    "#     left = 0 # Set the left-most edge\n",
    "#     upper = 0 # Set the top-most edge\n",
    "\n",
    "#     image_bboxes = []\n",
    "#     mask_bboxes = []\n",
    "    \n",
    "#     while (left < imageWidth):\n",
    "#         while (upper < imageHeight):\n",
    "#             # If the bottom and right of the cropping box overruns the image.\n",
    "#             if (upper + sliceHeight > imageHeight and \\\n",
    "#                 left + sliceWidth > imageWidth):\n",
    "#                 bbox = (left, upper, imageWidth, imageHeight)\n",
    "#             # If the right of the cropping box overruns the image\n",
    "#             elif (left + sliceWidth > imageWidth):\n",
    "#                 bbox = (left, upper, imageWidth, upper + sliceHeight)\n",
    "#             # If the bottom of the cropping box overruns the image\n",
    "#             elif (upper + sliceHeight > imageHeight):\n",
    "#                 bbox = (left, upper, left + sliceWidth, imageHeight)\n",
    "#             # If the entire cropping box is inside the image,\n",
    "#             # proceed normally.\n",
    "#             else:\n",
    "#                 bbox = (left, upper, left + sliceWidth, upper + sliceHeight)\n",
    "               \n",
    "#             image_bboxes.append(bbox)\n",
    "            \n",
    "#             upper += sliceHeight\n",
    "#         left += sliceWidth # Increment the vertical position\n",
    "#         upper = 0\n",
    "\n",
    "#     return image_bboxes\n",
    "\n",
    "\n",
    "\n",
    "def slice_imgs(imgs, masks, bboxes):\n",
    "        \n",
    "    total = len(imgs) * len (bboxes)\n",
    "    \n",
    "    imgs_slices = []\n",
    "    mask_slices = []\n",
    "\n",
    "    for index in tqdm(range(len(imgs))):\n",
    "\n",
    "        raw_img = imgs[index]\n",
    "        raw_mask = masks[index]\n",
    "            \n",
    "        for bbox in bboxes:\n",
    "            \n",
    "            img = raw_img.crop(bbox)\n",
    "            mask = raw_mask.crop(bbox)\n",
    "            \n",
    "            imgs_slices.append(img)\n",
    "            mask_slices.append(mask)\n",
    "            \n",
    "    imgs_slices = np.stack(imgs_slices)\n",
    "    mask_slices = np.stack(mask_slices)\n",
    "\n",
    "    return imgs_slices, mask_slices\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(50,448,448,3)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.mean(data)  # mean for data centering\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = sum(np.ravel((data - mean)**2))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_1 = np.random.rand(15,448,448,3)\n",
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_1 = np.mean(data_1)\n",
    "mean_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_1 = \n",
    "result_1sum(np.ravel((data_1 - mean_1)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_res = math.sqrt((result + result_1)/(65*448*448*3))\n",
    "total_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_data = np.concatenate([data,data_1])\n",
    "total_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.std(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(data_1.shape)\n",
    "print(np.ravel(data_1).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batches = [data,data_1]\n",
    "\n",
    "partial_results = []\n",
    "total_nr_examples = 0.\n",
    "\n",
    "for batch in batches:\n",
    "    total_nr_examples += len(np.ravel(batch))\n",
    "    mean = np.mean(batch)\n",
    "    partial_result = sum(np.ravel((batch - mean)**2))\n",
    "    partial_results.append(partial_result)\n",
    "    \n",
    "total_result = sum(partial_results)\n",
    "stddev =  math.sqrt( total_result / total_nr_examples)\n",
    "print(stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
